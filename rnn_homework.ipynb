{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all the input data has to be lowercase for the embeddings, it does not recoginize \"The\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Enhanced dataset with more variety\n",
    "sentences = [\n",
    "    \"The cat sat on the\", \"The dog ran around the\", \"The sun was shining in the\",\n",
    "    \"The baby laughed at the\", \"The teacher wrote on the\", \"A car drove over the\",\n",
    "    \"He opened the\", \"She closed the\", \"The player won the\", \"The artist drew a\",\n",
    "    \"The girl danced in the\", \"The boy played in the\", \"The wind blew through the\",\n",
    "    \"The author discussed the\", \"The scientist discovered a\", \"The historian studied the\",\n",
    "    \"The chef cooked a\", \"The farmer planted a\", \"The journalist wrote about the\",\n",
    "    \"The programmer debugged the\"\n",
    "]\n",
    "next_words = [\n",
    "    \"mat\", \"block\", \"sky\", \"toy\", \"board\", \"bridge\", \"door\", \"window\", \"game\", \"portrait\",\n",
    "    \"room\", \"yard\", \"trees\", \"topic\", \"method\", \"artifact\", \"dish\", \"seed\", \"event\", \"program\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({\"sentence\": sentences, \"next_word\": next_words})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "# Load GloVe Embeddings\n",
    "glove_file = \"glove.6B.100d.txt\"\n",
    "glove_embeddings = {}\n",
    "with open(glove_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = torch.tensor([float(x) for x in values[1:]], dtype=torch.float32)\n",
    "        glove_embeddings[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "df_json = pd.read_json('./dataset_rnn.json')\n",
    "# turn into dataframe make the right columns\n",
    "df = pd.DataFrame( columns=['sentence', 'next_word'])\n",
    "for i in range(len(df_json['data'])):\n",
    "    # no append\n",
    "    df.loc[i] = [df_json['data'][i]['sentence'].lower(), df_json['data'][i]['next_word'].lower()]\n",
    "'''\n",
    "This is only an example. Change as you see fit. Right now there is not split between train and test data. You will have to implement that.\n",
    "'''    \n",
    "\n",
    "\n",
    "\n",
    "# Assuming glove_embeddings has been loaded as shown earlier\n",
    "def sentence_to_embedding(sentence):\n",
    "    words = sentence.split()\n",
    "    embeddings = [glove_embeddings.get(word, torch.zeros(100, dtype=torch.float32)) for word in words]\n",
    "    return torch.stack(embeddings)\n",
    "\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        next_words = df[\"next_word\"].tolist()\n",
    "        self.word_to_idx = {word: i for i, word in enumerate(sorted(set(next_words)))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.df.iloc[idx, 0] \n",
    "        next_word = self.df.iloc[idx, 1] \n",
    "        embedding = sentence_to_embedding(sentence)\n",
    "        next_word_idx = self.word_to_idx[next_word]\n",
    "        return {\"sentence\": embedding, \"next_word\": next_word_idx}\n",
    "\n",
    "dataset = SentenceDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data randomly\n",
    "# split into 0.7, 0.15, 0.15\n",
    "# evaluate using k-fold cross evaluation\n",
    "\n",
    "# df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "data_len = len(df_json['data'])\n",
    "train_split = int(data_len * 0.7)\n",
    "test_split = train_split + int(data_len * 0.15)\n",
    "\n",
    "train_df = df.iloc[:train_split]\n",
    "test_df = df.iloc[train_split:test_split]\n",
    "val_df = df.iloc[test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.1249, Perplexity: 8.3717\n",
      "Epoch 2, Loss: 0.3114, Perplexity: 1.3653\n",
      "Epoch 3, Loss: 0.0739, Perplexity: 1.0767\n",
      "Epoch 4, Loss: 0.0269, Perplexity: 1.0273\n",
      "Epoch 5, Loss: 0.0136, Perplexity: 1.0137\n",
      "Epoch 6, Loss: 0.0086, Perplexity: 1.0086\n",
      "Epoch 7, Loss: 0.0062, Perplexity: 1.0062\n",
      "Epoch 8, Loss: 0.0048, Perplexity: 1.0048\n",
      "Epoch 9, Loss: 0.0038, Perplexity: 1.0038\n",
      "Epoch 10, Loss: 0.0031, Perplexity: 1.0031\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "# Load GloVe Embeddings\n",
    "glove_file = \"glove.6B.100d.txt\"\n",
    "glove_embeddings = {}\n",
    "with open(glove_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = torch.tensor([float(x) for x in values[1:]], dtype=torch.float32)\n",
    "        glove_embeddings[word] = vector\n",
    "import pandas as pd\n",
    "df_json = pd.read_json('./dataset_rnn.json')\n",
    "# turn into dataframe make the right columns\n",
    "df = pd.DataFrame( columns=['sentence', 'next_word'])\n",
    "for i in range(len(df_json['data'])):\n",
    "    # no append\n",
    "    df.loc[i] = [df_json['data'][i]['sentence'], df_json['data'][i]['next_word']]\n",
    "'''\n",
    "This is only an example. Change as you see fit. Right now there is not split between train and test data. You will have to implement that.\n",
    "'''    \n",
    "\n",
    "# Assuming glove_embeddings has been loaded as shown earlier\n",
    "def sentence_to_embedding(sentence):\n",
    "    words = sentence.split()\n",
    "    embeddings = [glove_embeddings.get(word, torch.zeros(100, dtype=torch.float32)) for word in words]\n",
    "    return torch.stack(embeddings)\n",
    "\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        next_words = df[\"next_word\"].tolist()\n",
    "        self.word_to_idx = {word: i for i, word in enumerate(sorted(set(next_words)))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.df.iloc[idx, 0]\n",
    "        next_word = self.df.iloc[idx, 1]\n",
    "        embedding = sentence_to_embedding(sentence)\n",
    "        next_word_idx = self.word_to_idx[next_word]\n",
    "        return {\"sentence\": embedding, \"next_word\": next_word_idx}\n",
    "\n",
    "dataset = SentenceDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim  # Save hidden_dim as an instance variable\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states with dimensions: (num_layers, batch_size, hidden_dim)\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_dim)\n",
    "        # Forward pass through LSTM layer\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        # Pass the output of the last time step to the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "output_dim = len(dataset.word_to_idx)  # Number of unique next words\n",
    "model = LSTMModel(input_dim=100, hidden_dim=128, output_dim=output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def calculate_perplexity(loss):\n",
    "    return torch.exp(loss)\n",
    "\n",
    "# Training Loop with Perplexity Calculation\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        model.train()\n",
    "        sentences = batch[\"sentence\"]\n",
    "        next_words = batch[\"next_word\"]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sentences)\n",
    "        loss = criterion(outputs, next_words)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    perplexity = calculate_perplexity(torch.tensor(avg_loss))\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Perplexity: {perplexity.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next word: mat\n"
     ]
    }
   ],
   "source": [
    "# check the model\n",
    "model.eval()\n",
    "sentence = \"The cat sat on the\"\n",
    "sentence_embedding = sentence_to_embedding(sentence).unsqueeze(0)\n",
    "output = model(sentence_embedding)\n",
    "_, predicted_idx = torch.max(output, 1)\n",
    "predicted_word = list(dataset.word_to_idx.keys())[predicted_idx.item()]\n",
    "print(f\"Predicted next word: {predicted_word}\")\n",
    "# Output: Predicted next word: mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sentence: The cat sat on the mat mat mat mat mat mat mat toy toy toy toy toy toy toy toy\n",
      "Generated Sentence: I am lucky to trees window block game trees trees trees trees trees seed trees trees trees trees sky dish\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "def generate_sentence(model, start_sentence, max_length=20):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    sentence = start_sentence\n",
    "    words = sentence.split()\n",
    "    return sentence\n",
    "\n",
    "# Example usage after training\n",
    "start_fragment = \"The cat sat on the\"\n",
    "generated_sentence = generate_sentence(model, start_fragment)\n",
    "#used_words = set(words)  # Keep track of words used in the sentence to apply penalties\n",
    "print(\"Generated Sentence:\", generated_sentence)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
